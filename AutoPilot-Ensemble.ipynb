{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::791580863750:role/service-role/AmazonSageMaker-ExecutionRole-20220707T123330\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "import pandas as pd\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "session = sagemaker.Session()\n",
    "bucket = 'lawsnic-aiml-east2'\n",
    "prefix = 'kaggle/customerChurn'\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "sm = boto3.Session().client(service_name='sagemaker',region_name=region)\n",
    "s3 =  boto3.Session().client(service_name='s3',region_name=region)\n",
    "\n",
    "train_data_uri = 's3://lawsnic-aiml-east2/kaggle/customerChurn/features/partial/train/CustomerChurnDW-2023-01-06T14-14-13/part-00000-642a0746-49b9-4fda-ad2d-98afe1db11ec-c000.csv'\n",
    "test_data_uri = 's3://lawsnic-aiml-east2/kaggle/customerChurn/features/partial/test/CustomerChurnDW-2023-01-06T14-14-13/part-00000-ccd6e4dd-898c-4fc4-a63a-85d1cfcfc4dc-c000.csv'\n",
    "test_data_uri_with_target = 's3://lawsnic-aiml-east2/kaggle/customerChurn/clarify/test_with_target.csv'\n",
    "\n",
    "train_data = pd.read_csv(train_data_uri);\n",
    "test_data = pd.read_csv(test_data_uri);\n",
    "\n",
    "train_data[\"SeniorCitizen\"] = train_data[\"SeniorCitizen\"].astype(int)\n",
    "train_data[\"Churn\"] = train_data[\"Churn\"].astype(int)\n",
    "train_data[\"Partner\"] = train_data[\"Partner\"].astype(int)\n",
    "train_data[\"Dependents\"] = train_data[\"Dependents\"].astype(int)\n",
    "train_data[\"PhoneService\"] = train_data[\"PhoneService\"].astype(int)\n",
    "train_data[\"PaperlessBilling\"] = train_data[\"PaperlessBilling\"].astype(int)\n",
    "train_data[\"isFemale\"] = train_data[\"isFemale\"].astype(int)\n",
    "train_data_uri = 's3://lawsnic-aiml-east2/kaggle/customerChurn/clarify/train.csv'\n",
    "train_data.to_csv(train_data_uri,index=False)\n",
    "\n",
    "test_data[\"SeniorCitizen\"] = test_data[\"SeniorCitizen\"].astype(int)\n",
    "test_data[\"Churn\"] = test_data[\"Churn\"].astype(int)\n",
    "test_data[\"Partner\"] = test_data[\"Partner\"].astype(int)\n",
    "test_data[\"Dependents\"] = test_data[\"Dependents\"].astype(int)\n",
    "test_data[\"PhoneService\"] = test_data[\"PhoneService\"].astype(int)\n",
    "test_data[\"PaperlessBilling\"] = test_data[\"PaperlessBilling\"].astype(int)\n",
    "test_data[\"isFemale\"] = test_data[\"isFemale\"].astype(int)\n",
    "test_data.to_csv('s3://lawsnic-aiml-east2/kaggle/customerChurn/clarify/test_with_target.csv',index=False)\n",
    "\n",
    "test_data2 =test_data.drop([\"Churn\"], axis=1)\n",
    "\n",
    "test_data_uri = 's3://lawsnic-aiml-east2/kaggle/customerChurn/clarify/test.csv'\n",
    "test_data2.to_csv(test_data_uri,index=False, header=False)\n",
    "\n",
    "\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data.head(10)\n",
    "#test_data.head(10)\n",
    "#train_data.columns.to_list()\n",
    "#test_data.columns.to_list()\n",
    "#train_data.count('columns')\n",
    "#test_data.count('columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_config = [{\n",
    "      'DataSource': {\n",
    "        'S3DataSource': {\n",
    "          'S3DataType': 'S3Prefix',\n",
    "          'S3Uri': train_data_uri\n",
    "        }\n",
    "      },\n",
    "      'ChannelType': 'training',    \n",
    "      'TargetAttributeName': 'Churn'\n",
    "    }     \n",
    "  ]\n",
    "\n",
    "output_data_config = {\n",
    "    'S3OutputPath': 's3://{}/{}/manual-output/autopilot-en'.format(bucket,prefix)\n",
    "  }\n",
    "\n",
    "autoMLJobConfig={\n",
    "        'CompletionCriteria': {\n",
    "            'MaxCandidates': 10\n",
    "        },\n",
    "        'Mode':'ENSEMBLING'\n",
    "}\n",
    "\n",
    "autoMLJobObjective = {\n",
    "    'MetricName': 'Precision'\n",
    "}\n",
    "\n",
    "test_data_s3_path = test_data_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launching the SageMaker Autopilot Job\n",
    "You can now launch the Autopilot job by calling the create_auto_ml_job API. https://docs.aws.amazon.com/cli/latest/reference/sagemaker/create-auto-ml-job.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoMLJobName: chn1677611865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AutoMLJobArn': 'arn:aws:sagemaker:us-east-2:791580863750:automl-job/chn1677611865',\n",
       " 'ResponseMetadata': {'RequestId': '938abb4d-a80d-42f3-9f52-6cc2454a7da0',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '938abb4d-a80d-42f3-9f52-6cc2454a7da0',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '84',\n",
       "   'date': 'Tue, 28 Feb 2023 19:17:46 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "auto_ml_job_name = 'chn' + str(int(time.time()))\n",
    "print('AutoMLJobName: ' + auto_ml_job_name)\n",
    "\n",
    "sm.create_auto_ml_job(AutoMLJobName=auto_ml_job_name,\n",
    "                      InputDataConfig=input_data_config,\n",
    "                      OutputDataConfig=output_data_config,\n",
    "                      AutoMLJobConfig=autoMLJobConfig,\n",
    "                      AutoMLJobObjective=autoMLJobObjective,\n",
    "                      ProblemType=\"BinaryClassification\",\n",
    "                      RoleArn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking SageMaker Autopilot job progress<a name=\"Tracking\"></a>\n",
    "SageMaker Autopilot job consists of the following high-level steps : \n",
    "* Analyzing Data, where the dataset is analyzed and Autopilot comes up with a list of ML pipelines that should be tried out on the dataset. The dataset is also split into train and validation sets.\n",
    "* Feature Engineering, where Autopilot performs feature transformation on individual features of the dataset as well as at an aggregate level.\n",
    "* Model Tuning, where the top performing pipeline is selected along with the optimal hyperparameters for the training algorithm (the last stage of the pipeline). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobStatus - Secondary Status\n",
      "------------------------------\n",
      "InProgress - TrainingModels\n",
      "InProgress - TrainingModels\n",
      "InProgress - TrainingModels\n",
      "InProgress - TrainingModels\n",
      "InProgress - TrainingModels\n",
      "InProgress - TrainingModels\n",
      "InProgress - TrainingModels\n",
      "InProgress - TrainingModels\n",
      "InProgress - TrainingModels\n",
      "InProgress - TrainingModels\n",
      "InProgress - TrainingModels\n",
      "InProgress - TrainingModels\n",
      "InProgress - TrainingModels\n",
      "InProgress - TrainingModels\n",
      "InProgress - TrainingModels\n",
      "InProgress - TrainingModels\n",
      "InProgress - TrainingModels\n",
      "InProgress - TrainingModels\n",
      "InProgress - TrainingModels\n",
      "InProgress - TrainingModels\n",
      "InProgress - TrainingModels\n",
      "InProgress - TrainingModels\n",
      "InProgress - TrainingModels\n",
      "InProgress - TrainingModels\n",
      "InProgress - TrainingModels\n",
      "InProgress - TrainingModels\n",
      "InProgress - TrainingModels\n",
      "InProgress - TrainingModels\n",
      "InProgress - TrainingModels\n",
      "InProgress - TrainingModels\n",
      "InProgress - TrainingModels\n",
      "InProgress - TrainingModels\n",
      "Completed - Completed\n"
     ]
    }
   ],
   "source": [
    "print ('JobStatus - Secondary Status')\n",
    "print('------------------------------')\n",
    "\n",
    "\n",
    "describe_response = sm.describe_auto_ml_job(AutoMLJobName=auto_ml_job_name)\n",
    "print (describe_response['AutoMLJobStatus'] + \" - \" + describe_response['AutoMLJobSecondaryStatus'])\n",
    "job_run_status = describe_response['AutoMLJobStatus']\n",
    "    \n",
    "while job_run_status not in ('Failed', 'Completed', 'Stopped'):\n",
    "    describe_response = sm.describe_auto_ml_job(AutoMLJobName=auto_ml_job_name)\n",
    "    job_run_status = describe_response['AutoMLJobStatus']\n",
    "    \n",
    "    print (describe_response['AutoMLJobStatus'] + \" - \" + describe_response['AutoMLJobSecondaryStatus'])\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Now use the describe_auto_ml_job API to look up the best candidate selected by the SageMaker Autopilot job. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sm.describe_auto_ml_job(AutoMLJobName=auto_ml_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "CandidateName: WeightedEnsemble-L2-FULL-t1791580863750chn1677611865\n",
      "FinalAutoMLJobObjectiveMetricName: Precision\n",
      "FinalAutoMLJobObjectiveMetricValue: 0.7345971465110779\n"
     ]
    }
   ],
   "source": [
    "best_candidate = sm.describe_auto_ml_job(AutoMLJobName=auto_ml_job_name)['BestCandidate']\n",
    "best_candidate_name = best_candidate['CandidateName']\n",
    "#print(best_candidate)\n",
    "print('\\n')\n",
    "print(\"CandidateName: \" + best_candidate_name)\n",
    "print(\"FinalAutoMLJobObjectiveMetricName: \" + best_candidate['FinalAutoMLJobObjectiveMetric']['MetricName'])\n",
    "print(\"FinalAutoMLJobObjectiveMetricValue: \" + str(best_candidate['FinalAutoMLJobObjectiveMetric']['Value']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CandidateName': 'WeightedEnsemble-L2-FULL-t1791580863750chn1677611865',\n",
       " 'FinalAutoMLJobObjectiveMetric': {'Type': 'Maximize',\n",
       "  'MetricName': 'Precision',\n",
       "  'Value': 0.7345971465110779,\n",
       "  'StandardMetricName': 'Precision'},\n",
       " 'ObjectiveStatus': 'Succeeded',\n",
       " 'CandidateSteps': [{'CandidateStepType': 'AWS::SageMaker::ProcessingJob',\n",
       "   'CandidateStepArn': 'arn:aws:sagemaker:us-east-2:791580863750:processing-job/chn1677611865-t1-1-ce6f3883c79a4556932c9cf8258d42a6bba35543204a',\n",
       "   'CandidateStepName': 'chn1677611865-t1-1-ce6f3883c79a4556932c9cf8258d42a6bba35543204a'}],\n",
       " 'CandidateStatus': 'Completed',\n",
       " 'InferenceContainers': [{'Image': '763104351884.dkr.ecr.us-east-2.amazonaws.com/autogluon-inference:0.4.3-cpu-py38-ubuntu20.04',\n",
       "   'ModelDataUrl': 's3://lawsnic-aiml-east2/kaggle/customerChurn/manual-output/autopilot-en/chn1677611865/sagemaker-automl-candidates/model/WeightedEnsemble-L2-FULL-t1/model.tar.gz',\n",
       "   'Environment': {'MODEL_NAME': 'WeightedEnsemble-L2-FULL',\n",
       "    'SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT': 'text/csv',\n",
       "    'SAGEMAKER_INFERENCE_OUTPUT': 'predicted_label',\n",
       "    'SAGEMAKER_INFERENCE_SUPPORTED': 'predicted_label,probability,probabilities,labels',\n",
       "    'SAGEMAKER_PROGRAM': 'tabular_serve.py',\n",
       "    'SAGEMAKER_SUBMIT_DIRECTORY': '/opt/ml/model/code'}}],\n",
       " 'CreationTime': datetime.datetime(2023, 2, 28, 19, 18, 15, tzinfo=tzlocal()),\n",
       " 'EndTime': datetime.datetime(2023, 2, 28, 19, 33, 25, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2023, 2, 28, 19, 33, 35, 693000, tzinfo=tzlocal()),\n",
       " 'CandidateProperties': {'CandidateArtifactLocations': {'Explainability': 's3://lawsnic-aiml-east2/kaggle/customerChurn/manual-output/autopilot-en/chn1677611865/documentation/explainability/output/chn1677611865-t1-1-ce6f3883c79a4556932c9cf8258d42a6bba35543204a',\n",
       "   'ModelInsights': 's3://lawsnic-aiml-east2/kaggle/customerChurn/manual-output/autopilot-en/chn1677611865/documentation/model_monitor/output/WeightedEnsemble-L2-FULL-t1791580863750chn1677611865'},\n",
       "  'CandidateMetrics': [{'MetricName': 'Accuracy',\n",
       "    'Value': 0.8107255697250366,\n",
       "    'Set': 'Validation',\n",
       "    'StandardMetricName': 'Accuracy'},\n",
       "   {'MetricName': 'F1',\n",
       "    'Value': 0.5636363625526428,\n",
       "    'Set': 'Validation',\n",
       "    'StandardMetricName': 'F1'},\n",
       "   {'MetricName': 'BalancedAccuracy',\n",
       "    'Value': 0.6984736323356628,\n",
       "    'Set': 'Validation',\n",
       "    'StandardMetricName': 'BalancedAccuracy'},\n",
       "   {'MetricName': 'AUC',\n",
       "    'Value': 0.8542855381965637,\n",
       "    'Set': 'Validation',\n",
       "    'StandardMetricName': 'AUC'},\n",
       "   {'MetricName': 'Precision',\n",
       "    'Value': 0.7345971465110779,\n",
       "    'Set': 'Validation',\n",
       "    'StandardMetricName': 'Precision'},\n",
       "   {'MetricName': 'Recall',\n",
       "    'Value': 0.4572271406650543,\n",
       "    'Set': 'Validation',\n",
       "    'StandardMetricName': 'Recall'},\n",
       "   {'MetricName': 'LogLoss',\n",
       "    'Value': 0.41862526535987854,\n",
       "    'Set': 'Validation',\n",
       "    'StandardMetricName': 'LogLoss'},\n",
       "   {'MetricName': 'InferenceLatency',\n",
       "    'Value': 0.2365294247865677,\n",
       "    'Set': 'Validation',\n",
       "    'StandardMetricName': 'InferenceLatency'}]}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ARN corresponding to the best candidate is : arn:aws:sagemaker:us-east-2:791580863750:model/automl-custchurn-model-1677698200\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'model_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-0ceead76761d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model ARN corresponding to the best candidate is : {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ModelArn'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'model_data'"
     ]
    }
   ],
   "source": [
    "model_name = 'automl-custChurn-model-' + str(int(time.time()))\n",
    "\n",
    "model = sm.create_model(Containers=best_candidate['InferenceContainers'],\n",
    "                            ModelName=model_name,\n",
    "                            ExecutionRoleArn=role)\n",
    "\n",
    "print('Model ARN corresponding to the best candidate is : {}'.format(model['ModelArn']))\n",
    "\n",
    "#print(model.model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the best model with Model Registry\n",
    "\n",
    "#### Create model group "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelPackageGroup Arn : arn:aws:sagemaker:us-east-2:791580863750:model-package-group/custchurndemo\n"
     ]
    }
   ],
   "source": [
    "# Create a Model Package Group: https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry-model-group.html\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "\n",
    "model_package_group_name = \"custChurnDemo\" \n",
    "model_package_group_input_dict = {\n",
    "    \"ModelPackageGroupName\": model_package_group_name,\n",
    "    \"ModelPackageGroupDescription\": \"Model package group for xgboost regression model with Abalone dataset\",\n",
    "}\n",
    "\n",
    "#create_model_pacakge_group_response = sm.create_model_package_group(\n",
    "    **model_package_group_input_dict\n",
    ")\n",
    "print(\n",
    "    \"ModelPackageGroup Arn : {}\".format(create_model_pacakge_group_response[\"ModelPackageGroupArn\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_group_arn = create_model_pacakge_group_response[\"ModelPackageGroupArn\"]\n",
    "modelpackage_inference_specification = {\n",
    "    \"InferenceSpecification\": {\n",
    "        \"Containers\": [\n",
    "            {\n",
    "                \"Image\": best_candidate['InferenceContainers'][0]['Image'],\n",
    "            }\n",
    "        ],\n",
    "        \"SupportedContentTypes\": [\"text/csv\"],\n",
    "        \"SupportedResponseMIMETypes\": [\"text/csv\"],\n",
    "    }\n",
    "}\n",
    "\n",
    "# Specify the model source\n",
    "model_url = best_candidate['InferenceContainers'][0]['ModelDataUrl']\n",
    "model_env = best_candidate['InferenceContainers'][0]['Environment']\n",
    "\n",
    "# Specify the model data\n",
    "modelpackage_inference_specification[\"InferenceSpecification\"][\"Containers\"][0][\n",
    "    \"ModelDataUrl\"\n",
    "] = model_url\n",
    "\n",
    "modelpackage_inference_specification[\"InferenceSpecification\"][\"Containers\"][0][\n",
    "     \"Environment\"\n",
    "] = model_env\n",
    "\n",
    "create_model_package_input_dict = {\n",
    "    \"ModelPackageGroupName\": model_package_group_arn,\n",
    "    \"ModelPackageDescription\": \"Model for regression with the Abalone dataset\",\n",
    "    \"ModelApprovalStatus\": \"Approved\",\n",
    "}\n",
    "create_model_package_input_dict.update(modelpackage_inference_specification)\n",
    "\n",
    "#print(create_model_package_input_dict)\n",
    "\n",
    "# Create cross-account model package\n",
    "create_mode_package_response = sm.create_model_package(**create_model_package_input_dict)\n",
    "model_package_arn = create_mode_package_response[\"ModelPackageArn\"]\n",
    "#print(\"ModelPackage Version ARN : {}\".format(model_package_arn))\n",
    "#print(create_mode_package_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrive the model back from Registry to do batch inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ModelPackageGroupName': 'custChurnDemo', 'ModelPackageVersion': 5, 'ModelPackageArn': 'arn:aws:sagemaker:us-east-2:791580863750:model-package/custchurndemo/5', 'ModelPackageDescription': 'Model for regression with the Abalone dataset', 'CreationTime': datetime.datetime(2023, 3, 1, 21, 39, 15, 965000, tzinfo=tzlocal()), 'InferenceSpecification': {'Containers': [{'Image': '763104351884.dkr.ecr.us-east-2.amazonaws.com/autogluon-inference:0.4.3-cpu-py38-ubuntu20.04', 'ImageDigest': 'sha256:f461d5f846f9e2f30db9ee57ff6fa6c8ba2263f8cf343f031e1c178a6b6af864', 'ModelDataUrl': 's3://lawsnic-aiml-east2/kaggle/customerChurn/manual-output/autopilot-en/chn1677611865/sagemaker-automl-candidates/model/WeightedEnsemble-L2-FULL-t1/model.tar.gz', 'Environment': {'MODEL_NAME': 'WeightedEnsemble-L2-FULL', 'SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT': 'text/csv', 'SAGEMAKER_INFERENCE_OUTPUT': 'predicted_label', 'SAGEMAKER_INFERENCE_SUPPORTED': 'predicted_label,probability,probabilities,labels', 'SAGEMAKER_PROGRAM': 'tabular_serve.py', 'SAGEMAKER_SUBMIT_DIRECTORY': '/opt/ml/model/code'}}], 'SupportedContentTypes': ['text/csv'], 'SupportedResponseMIMETypes': ['text/csv']}, 'ModelPackageStatus': 'Completed', 'ModelPackageStatusDetails': {'ValidationStatuses': [], 'ImageScanStatuses': []}, 'CertifyForMarketplace': False, 'ModelApprovalStatus': 'Approved', 'CreatedBy': {'UserProfileArn': 'arn:aws:sagemaker:us-east-2:791580863750:user-profile/d-lck5z2rioius/default-1657211579981', 'UserProfileName': 'default-1657211579981', 'DomainId': 'd-lck5z2rioius'}, 'ResponseMetadata': {'RequestId': '4487fee0-ef74-4f15-8883-df9c34bdfe2d', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '4487fee0-ef74-4f15-8883-df9c34bdfe2d', 'content-type': 'application/x-amz-json-1.1', 'content-length': '1612', 'date': 'Wed, 01 Mar 2023 21:51:45 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "pkg_list = sm.list_model_packages(ModelPackageGroupName=model_package_group_name,\n",
    "                                         ModelPackageType='Versioned',\n",
    "                                         SortBy='CreationTime',\n",
    "                                         SortOrder='Descending',\n",
    "                                         #NameContains=str(model_package_version)\n",
    "                                          )\n",
    "\n",
    "#print(pkg_list['ModelPackageSummaryList'][0])\n",
    "print(sm.describe_model_package(ModelPackageName=pkg_list['ModelPackageSummaryList'][0]['ModelPackageArn']))\n",
    "\n",
    "pkg_description = sm.describe_model_package(ModelPackageName=pkg_list['ModelPackageSummaryList'][0]['ModelPackageArn'])\n",
    "\n",
    "pkg_model_arn = pkg_list['ModelPackageSummaryList'][0]['ModelPackageArn']\n",
    "\n",
    "# Create a Model object from the retrieved model package\n",
    "pkg_model = sagemaker.ModelPackage(model_package_arn=pkg_model_arn,\n",
    "                               role=role,\n",
    "                               sagemaker_session=session)\n",
    "\n",
    "#print(pkg_model)\n",
    "#print(type(pkg_model))\n",
    "#print(pkg_model.__dict__)\n",
    "\n",
    "#import json\n",
    "#json.dumps(pkg_model.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry_model_name = 'latestCustChurnRegisteredPkg4'\n",
    "testModel = sm.create_model(\n",
    "    ModelName = registry_model_name,\n",
    "    Containers = [\n",
    "        {\n",
    "            'Image': pkg_description['InferenceSpecification']['Containers'][0]['Image'],\n",
    "            'Mode': 'SingleModel',\n",
    "            'ModelDataUrl': pkg_description['InferenceSpecification']['Containers'][0]['ModelDataUrl'],\n",
    "            \n",
    "            #attempt 4.1 changing this to the env passed into the register\n",
    "            #'Environment': {\"MMS_DEFAULT_WORKERS_PER_MODEL\": '1'}\n",
    "            'Environment':pkg_description['InferenceSpecification']['Containers'][0]['Environment'],\n",
    "        }\n",
    "    ],\n",
    "    ExecutionRoleArn = role\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#registry_model_name = 'latestCustChurnRegisteredPkg2'\n",
    "#print(testModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform batch inference using the best candidate\n",
    "\n",
    "Now that you have successfully completed the SageMaker Autopilot job on the dataset, create a model from any of the candidates by using [Inference Pipelines](https://docs.aws.amazon.com/sagemaker/latest/dg/inference-pipelines.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime, sleep \n",
    "from sagemaker.inputs import BatchDataCaptureConfig\n",
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "timestamp_suffix = strftime('%d-%H-%M-%S', gmtime())\n",
    "\n",
    "transform_job_name = 'registry-custchurn-tr-' + timestamp_suffix\n",
    "\n",
    "transform_input = {\n",
    "        'DataSource': {\n",
    "            'S3DataSource': {\n",
    "                'S3DataType': 'S3Prefix',\n",
    "                #'S3Uri': test_data_uri\n",
    "                'S3Uri': test_data_uri\n",
    "            }\n",
    "        },\n",
    "        'ContentType': 'text/csv',\n",
    "        'CompressionType': 'None',\n",
    "        'SplitType': 'Line'\n",
    "    }\n",
    "\n",
    "transform_output = {\n",
    "        'S3OutputPath': 's3://{}/{}/inference-results'.format(bucket,prefix),\n",
    "        \"Accept\": \"text/csv\",\n",
    "        'AssembleWith': 'Line',\n",
    "    }\n",
    "\n",
    "transform_resources = {\n",
    "        'InstanceType': 'ml.m5.4xlarge',\n",
    "        'InstanceCount': 1\n",
    "    }\n",
    "\n",
    "data_capture_config = {\n",
    "       \"DestinationS3Uri\": 's3://{}/{}/model-monitor/batch-results'.format(bucket,prefix), \n",
    "       \"GenerateInferenceId\": True,\n",
    "    }\n",
    "\n",
    "data_proc = { \n",
    "        \"JoinSource\": \"Input\"\n",
    "        }\n",
    "\n",
    "#original transform job pulling the model directly from AutoPilot - should always work or we have a problem\n",
    "#transformer = sm.create_transform_job(TransformJobName = transform_job_name,\n",
    "#                        ModelName = model_name,\n",
    "#                        TransformInput = transform_input,\n",
    "#                        TransformOutput = transform_output,\n",
    "#                        TransformResources = transform_resources,\n",
    "#                        DataCaptureConfig= data_capture_config,\n",
    "#                        DataProcessing = data_proc\n",
    "#)\n",
    "\n",
    "#this method fails due to modelName >63 characters\n",
    "#transformer = transformer = sagemaker.transformer.Transformer(\n",
    "#                        model_name=pkg_model_arn,\n",
    "#                        base_transform_job_name = transform_job_name,\n",
    "#                        instance_type='ml.m5.4xlarge',\n",
    "#                        instance_count=1, \n",
    "#                        output_path='s3://{}/{}/inference-results'.format(bucket,prefix),\n",
    "#)\n",
    "\n",
    "\n",
    "##this is using the modelPkg obj built in transformer obj\n",
    "#transformer = pkg_model.transformer(  \n",
    "#                        instance_type='ml.m5.4xlarge', \n",
    "#                        instance_count=1, \n",
    "#                        output_path='s3://{}/{}/inference-results'.format(bucket,prefix),\n",
    "#)\n",
    "\n",
    "# Start the batch transform job\n",
    "#transformer.transform(test_data_uri, content_type='text/csv', split_type='Line')\n",
    "\n",
    "#attempt 4 - created a model the old way but using the info from pkg_model describe function\n",
    "#attempt 4.1 - now passing in the Environment config to the modelRegister when creating entry\n",
    "transformer = sm.create_transform_job(TransformJobName = transform_job_name,\n",
    "                        ModelName = registry_model_name,\n",
    "                        TransformInput = transform_input,\n",
    "                        TransformOutput = transform_output,\n",
    "                        TransformResources = transform_resources,\n",
    "                        DataCaptureConfig= data_capture_config,\n",
    "                        DataProcessing = data_proc,\n",
    "                        #Environment= { \n",
    "                        #    \"SAGEMAKER_PROGRAM\":\"inference.py\",\n",
    "                        #    \"SAGEMAKER_SUBMIT_DIRECTORY\":\"/opt/ml/model/code\",\n",
    "                        #    \"SAGEMAKER_CONTAINER_LOG_LEVEL\":\"20\",\n",
    "                        #    \"SAGEMAKER_REGION\": 'us-east-2'\n",
    "                        #}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobStatus\n",
      "----------\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "print ('JobStatus')\n",
    "print('----------')\n",
    "\n",
    "\n",
    "describe_response = sm.describe_transform_job(TransformJobName = transform_job_name)\n",
    "job_run_status = describe_response['TransformJobStatus']\n",
    "print (job_run_status)\n",
    "\n",
    "while job_run_status not in ('Failed', 'Completed', 'Stopped'):\n",
    "    describe_response = sm.describe_transform_job(TransformJobName = transform_job_name)\n",
    "    job_run_status = describe_response['TransformJobStatus']\n",
    "    print (job_run_status)\n",
    "    sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output_key = '{}/inference-results/test.csv.out'.format(prefix);\n",
    "local_inference_results_path = 'inference_results.csv'\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "inference_results_bucket = s3.Bucket(bucket)\n",
    "\n",
    "print(s3_output_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_results_bucket.download_file(s3_output_key, local_inference_results_path);\n",
    "\n",
    "data = pd.read_csv(local_inference_results_path, sep=';')\n",
    "pd.set_option('display.max_rows', 10)         # Keep the output on one page\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
